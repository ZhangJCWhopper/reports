What they do:
	First, talk about the cluster on MFCC features, this method goes like clustering of the MFCC vectors using K-means method, and then use the cluster core to make the KNN graph (link the k-nearest neighbours) and then use the maximum common subgraph (MCS), matching and align the testing speech graph to the enrolled ones and then get the matching score(counting percentage: MCS/original graph). The dataset is NIST SRE1999, the least EER is 13.8%, achieved when the graph has 64 vertices. Model size larger than 128 was not tested as the computational cost is unachievable.  
	My comments: An important point of this kind of method is, the MCS ensures that the method to get the matching score is robust to rotation, which is common in text-independent situation. But using this is far less than enough, as roatation is just one of the problems brought by text-independent situation. In addition, the matching method would consume great amount of time and resource. From this I can learn that directly make clusters, graphes on the spectral field(MFCC) seems not to be a good idea.
	Then, talk about another kind of method. The graph' structure goes like: each vertex represents a speech sample, and the edges are established in the training period based on: 1) the speaker of the speech, 2) the difference among the samples, 3) the distribution: one speaker has how many related speech samples
	My comments: In this set of methods, the graph is used to represent the inter-speech relation, so shortest distance instead of graph match methods are used in this kind of situation. But we can learn something from the methods used to esablish the edges in the graph.

So what can I do:
I think my approach would be more similar to the first kind of the research. However, its results is not good. In the following days, what I want to try first is: use the spectral graph methods to replace the maximum common subgraph(MCS). This would lead to the cut of the computational cost, and so I can use more nodes(in other words, number of clusters of one speech sample) in one graph, (in Tommi's case the computational complexity is square).
Then, after finishing this, talk to Choi-san about getting rid of text-realted information from the speech, make the graph better related to speaker information.
